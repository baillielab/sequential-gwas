var documenterSearchIndex = {"docs":
[{"location":"mock_data/#Mock-Data","page":"Mock Data","title":"Mock Data","text":"","category":"section"},{"location":"mock_data/","page":"Mock Data","title":"Mock Data","text":"In order to ease testing and development, we generate mock data that closely ressembles the original data while preserving the privacy of individuals in the cohorts. This page explains how this is done.","category":"page"},{"location":"mock_data/","page":"Mock Data","title":"Mock Data","text":"First but foremost, for all individuals, a mock sample ID is created. Since there is no sensitive information about individuals, these cannot be identified as long as the genetic data is perturbed. We explain below how this is done.","category":"page"},{"location":"mock_data/#Genotyping-Arrays","page":"Mock Data","title":"Genotyping Arrays","text":"","category":"section"},{"location":"mock_data/","page":"Mock Data","title":"Mock Data","text":"Only a subset of genetic variations are kept (e.g. 100 out of 500 000)\nFor each individual, each variant is resampled independently from the cohort's empirical distribution. The probability of this operation to have no effect on an individual is difficult to estimate since it depends on each variant's alleles frequencies. If all variants were different it would be (1/n_samples)^nvariants which for the lower values of nsamples=1000 and nvariants=110, this is lower than 10^-300.","category":"page"},{"location":"mock_data/#Whole-Genome-Sequencing","page":"Mock Data","title":"Whole Genome Sequencing","text":"","category":"section"},{"location":"mock_data/","page":"Mock Data","title":"Mock Data","text":"The GVCF mock data arising from whole genome sequencing is built from a very small intersection of variants (e.g., 100) common to all genotyping arrays. Individuals are thus unidentifiable.","category":"page"},{"location":"mock_data/#Covariates","page":"Mock Data","title":"Covariates","text":"","category":"section"},{"location":"mock_data/","page":"Mock Data","title":"Mock Data","text":"Since the covariates are not sensitive, the newly created odap identifier is simply forwarded to covariates.","category":"page"},{"location":"mock_data/#How-to-Mock","page":"Mock Data","title":"How to Mock","text":"","category":"section"},{"location":"mock_data/","page":"Mock Data","title":"Mock Data","text":"To run, on ODAP, assuming:","category":"page"},{"location":"mock_data/","page":"Mock Data","title":"Mock Data","text":"The data output by Dominique is in /odp-beefgs/a015/linked_data/preqc/array-pre-imputation/ and mounted in the singularity container in /mnt/data\nThe repo is mounted in /mnt/genomicc-workflows (This is not necessary anymore once the code is in the container, just need to point to /opt/genomicc-workflows)","category":"page"},{"location":"mock_data/","page":"Mock Data","title":"Mock Data","text":"singularity shell --bind /odp-beefgs/a015/linked_data/preqc/array-pre-imputation/:/mnt/data PATH_TO_SINGULARITY_IMAGE","category":"page"},{"location":"mock_data/","page":"Mock Data","title":"Mock Data","text":"Then run ","category":"page"},{"location":"mock_data/","page":"Mock Data","title":"Mock Data","text":"JULIA_DEPOT_PATH=$JULIA_DEPOT_PATH:/root/.julia julia --project=/opt/genomicc-workflows /opt/genomicc-workflows/bin/genomicc.jl","category":"page"},{"location":"mock_data/","page":"Mock Data","title":"Mock Data","text":"I also manually:","category":"page"},{"location":"mock_data/","page":"Mock Data","title":"Mock Data","text":"Added duplicate sample IDs to reproduce what is in the data.\nChanged the position of GSA-rs114361133 in test/assets/genomicc/genotyping_arrays/mock.release_2021_2023.map to be unliftable.","category":"page"},{"location":"mock_data/#Thousands-Genomes","page":"Mock Data","title":"Thousands Genomes","text":"","category":"section"},{"location":"mock_data/","page":"Mock Data","title":"Mock Data","text":"The data was downloaded from the 1000GP FTP and pruned using the bin/make_thousand_genomes_filter_files.jl script.","category":"page"},{"location":"development/#Development","page":"Development","title":"Development","text":"","category":"section"},{"location":"development/","page":"Development","title":"Development","text":"This page contains some tips and tricks to help development. Because of the difficulty associated with development on ODAP it is assumed that most of the development will take place outside of it. For that purpose the original data has been mocked and is stored in test/assets. More information on the process can be found in Mock Data","category":"page"},{"location":"development/#Build-Docker-Image","page":"Development","title":"Build Docker Image","text":"","category":"section"},{"location":"development/","page":"Development","title":"Development","text":"The image is built automatically during the continuous integration process and published on Docker HUB.","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"You can also build it locally if you have docker installed by running the following:","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"docker build -t genomicc-workflows -f docker/Dockerfile .","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"(If running on MacOS with an ARM platform, add: --platform linux/amd64)","category":"page"},{"location":"development/#Code-Development-on-ODAP2","page":"Development","title":"Code Development on ODAP2","text":"","category":"section"},{"location":"development/","page":"Development","title":"Development","text":"When you really need to.","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"First import the docker image as a singularity container within ODAP which we assume is called genomicc-workflows.sif.","category":"page"},{"location":"development/#Julia-REPL","page":"Development","title":"Julia REPL","text":"","category":"section"},{"location":"development/","page":"Development","title":"Development","text":"To get a shell while mounting the repo within the container:","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"singularity shell --bind $PWD:/mnt/genomicc-workflows genomicc-workflows.sif","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"singularity shell --bind $PWD:/mnt/genomicc-workflows genomicc-workflows.sif ","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"Then run the julia REPL","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"JULIA_DEPOT_PATH=$JULIA_DEPOT_PATH:/root/.julia julia --project=/mnt/genomicc-workflows","category":"page"},{"location":"development/#Extra-Tools","page":"Development","title":"Extra Tools","text":"","category":"section"},{"location":"development/","page":"Development","title":"Development","text":"Most tools are available within their conda environment, for instance regenie:","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"docker run -it --rm genomicc-workflows /opt/miniforge3/bin/mamba run -n regenie_env regenie --help","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"(If running on MacOS with arm platform, add: --platform linux/amd64)","category":"page"},{"location":"development/#UKB-RAP","page":"Development","title":"UKB RAP","text":"","category":"section"},{"location":"development/#Cloud-Workstation","page":"Development","title":"Cloud Workstation","text":"","category":"section"},{"location":"development/","page":"Development","title":"Development","text":"To debug errors, it may be useful to run the code interactively, for this, you can use the Cloud Workstation. This tutorial may also be useful. To start an instance:","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"dx run \\\n  --instance-type mem1_ssd1_v2_x16 \\\n  -imax_session_length=\"10h\" \\\n  -y \\\n  --ssh app-cloud_workstation","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"To import one or multiple files:","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"dx download file-J1P9y88JjZjXfq4Y5gYBxk86 file-J1P9y88JjZjbX18xFZ38qY2P","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"Then you can download the docker image and enter a container:","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"docker run -it --rm -v $PWD:/mnt/data olivierlabayle/genomicc:main /bin/bash","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"The current directory is mounted to /mnt/data. From there, work as usual, for instance to start a Julia REPL:","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"julia --project=/opt/genomicc-workflows --sysimage=/opt/genomicc-workflows/GenomiccWorkflows.so --startup-file=no","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"Finally, when you are finished, terminate the job with the appropriate job-id:","category":"page"},{"location":"development/","page":"Development","title":"Development","text":"dx terminate job-J1V4870JpYQP94jgb33y45qP","category":"page"},{"location":"walk_through/#Walk-Through","page":"Walk Through","title":"Walk Through","text":"","category":"section"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"In this section we discuss how to regenerate results from an analysis from scratch. Each step consists in a separate workflow for which a dedicated documentation is referenced. While workflows are platform agnostic, due to complex data permissions and governance, each workflow is typically run on a dedicated platform.","category":"page"},{"location":"walk_through/#Step-1:-Aggregating-Genetic-Datasets","page":"Walk Through","title":"Step 1: Aggregating Genetic Datasets","text":"","category":"section"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"workflow: Combining GenOMICC Datasets\nplatform: Working with ODAP","category":"page"},{"location":"walk_through/#Step-2:-Imputation-of-Genotypes","page":"Walk Through","title":"Step 2: Imputation of Genotypes","text":"","category":"section"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"workflow: GenOMICC Genotypes Imputation\nplatform: Eddie","category":"page"},{"location":"walk_through/#Step-3:-Merging-GenOMICC-and-the-UK-Biobank","page":"Walk Through","title":"Step 3: Merging GenOMICC and the UK Biobank","text":"","category":"section"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"workflow: Merging the GenOMICC and UK Biobank Cohorts\nplatform: Working with the UKB RAP","category":"page"},{"location":"walk_through/#Step-4:-Analysis","page":"Walk Through","title":"Step 4: Analysis","text":"","category":"section"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"workflow: Todo\nplatform: Working with the UKB RAP","category":"page"},{"location":"odap_prerequisites/#Working-with-ODAP","page":"ODAP","title":"Working with ODAP","text":"","category":"section"},{"location":"odap_prerequisites/#Platform:-ODAP","page":"ODAP","title":"Platform: ODAP","text":"","category":"section"},{"location":"odap_prerequisites/","page":"ODAP","title":"ODAP","text":"Since the data is sensitive, it is meant to run on the ODAP platform (at least for now). To get access, you will need to contact the relevant person, at the moment dominique.mccormick@ed.ac.uk. More information on accessing ODAP can be found here.","category":"page"},{"location":"odap_prerequisites/#Software","page":"ODAP","title":"Software","text":"","category":"section"},{"location":"odap_prerequisites/","page":"ODAP","title":"ODAP","text":"In order to run the workflows in this repository only 2 software need to be installed, and they should already be present on ODAP:","category":"page"},{"location":"odap_prerequisites/","page":"ODAP","title":"ODAP","text":"Nextflow 24.10.3 (see how to setup)\nSingularity 3.9.4 (Should be ready to use)","category":"page"},{"location":"odap_prerequisites/#Importing-Into-ODAP","page":"ODAP","title":"Importing Into ODAP","text":"","category":"section"},{"location":"odap_prerequisites/","page":"ODAP","title":"ODAP","text":"In order to upload the current state of the code, or a specific version of genomicc-workflows into ODAP, we currently proceed via a shared folder with Dominique.","category":"page"},{"location":"odap_prerequisites/#Locally","page":"ODAP","title":"Locally","text":"","category":"section"},{"location":"odap_prerequisites/","page":"ODAP","title":"ODAP","text":"The following assumes a specific git tag corresponding to a release for which a matching docker image exists, but the steps can be adapted to any need.","category":"page"},{"location":"odap_prerequisites/","page":"ODAP","title":"ODAP","text":"export genomicc_workflows_tag=\"main\"","category":"page"},{"location":"odap_prerequisites/","page":"ODAP","title":"ODAP","text":"In the shared folder.","category":"page"},{"location":"odap_prerequisites/","page":"ODAP","title":"ODAP","text":"Clone the repository or the relevant commit or tag:","category":"page"},{"location":"odap_prerequisites/","page":"ODAP","title":"ODAP","text":"git clone git@github.com:baillielab/genomicc-workflows.git\ngit checkout $genomicc_workflows_tag","category":"page"},{"location":"odap_prerequisites/","page":"ODAP","title":"ODAP","text":"Download and save the docker image","category":"page"},{"location":"odap_prerequisites/","page":"ODAP","title":"ODAP","text":"docker pull --platform linux/amd64 olivierlabayle/genomicc:$genomicc_workflows_tag\ndocker save olivierlabayle/genomicc:$genomicc_workflows_tag | gzip > genomicc-workflows/genomicc.tar.gz","category":"page"},{"location":"odap_prerequisites/","page":"ODAP","title":"ODAP","text":"Then ask Dominique to uplaod the folder to ODAP.","category":"page"},{"location":"odap_prerequisites/#On-ODAP","page":"ODAP","title":"On ODAP","text":"","category":"section"},{"location":"odap_prerequisites/","page":"ODAP","title":"ODAP","text":"In the uploaded repository, build the singularity image:","category":"page"},{"location":"odap_prerequisites/","page":"ODAP","title":"ODAP","text":"gunzip genomicc.tar.gz && singularity build genomicc.sif docker-archive:genomicc.tar","category":"page"},{"location":"rap_prerequisites/#Working-with-the-UKB-RAP","page":"UKB RAP","title":"Working with the UKB RAP","text":"","category":"section"},{"location":"rap_prerequisites/","page":"UKB RAP","title":"UKB RAP","text":"Most of the interactions with the UK Biobank RAP is made directly from your local machine using the dx-toolkit.","category":"page"},{"location":"rap_prerequisites/#Installing-Dependencies","page":"UKB RAP","title":"Installing Dependencies","text":"","category":"section"},{"location":"rap_prerequisites/#DNA-Nexus-Toolkit","page":"UKB RAP","title":"DNA Nexus Toolkit","text":"","category":"section"},{"location":"rap_prerequisites/","page":"UKB RAP","title":"UKB RAP","text":"First, install the dx-toolkit on your local computer by following the instructions on this page. You will also need to download the compiler.","category":"page"},{"location":"rap_prerequisites/","page":"UKB RAP","title":"UKB RAP","text":"For reference, a quickstart guide to the toolkit can also be found here.","category":"page"},{"location":"rap_prerequisites/#Installing-miniwdl-(Optional)","page":"UKB RAP","title":"Installing miniwdl (Optional)","text":"","category":"section"},{"location":"rap_prerequisites/","page":"UKB RAP","title":"UKB RAP","text":"If you want to check the workflow syntax and run the make check operations, you can also download miniwdl.","category":"page"},{"location":"rap_prerequisites/#Cromwell-(If-you-want-to-develop)","page":"UKB RAP","title":"Cromwell (If you want to develop)","text":"","category":"section"},{"location":"rap_prerequisites/","page":"UKB RAP","title":"UKB RAP","text":"To run WDL workflows locally you will need cromwell as well. If you are planning to extend the capabilities of this package, this page will be of interest.","category":"page"},{"location":"rap_prerequisites/#Logging-in","page":"UKB RAP","title":"Logging in","text":"","category":"section"},{"location":"rap_prerequisites/","page":"UKB RAP","title":"UKB RAP","text":"Then you need to login to your UKB RAP account using:","category":"page"},{"location":"rap_prerequisites/","page":"UKB RAP","title":"UKB RAP","text":"dx login","category":"page"},{"location":"rap_prerequisites/","page":"UKB RAP","title":"UKB RAP","text":"You will be prompted for your username and password.","category":"page"},{"location":"misc/#Further-Information","page":"Further Information","title":"Further Information","text":"","category":"section"},{"location":"misc/","page":"Further Information","title":"Further Information","text":"(To be moved/updated to an appropriate place)","category":"page"},{"location":"misc/","page":"Further Information","title":"Further Information","text":"The Illumina manifest files corresponding to each array can be downloaded from Illumina's website. The description of the manifest columns can be found here. A comparison of both the GSA-48v4 and GSA-24v3 arrays for the GRC38 genome build yields the following table (function GenomiccWorkflows.OneTimeChecks.array_overlap): ","category":"page"},{"location":"misc/","page":"Further Information","title":"Further Information","text":"Description Number of SNPs\nIn GSA-48v4 650 321\nIn GSA-24v3 654 027\nUnion 702 515\nIntersection 601 833\nOnly in GSA-48v4 48 488\nOnly in GSA-24v3 52 194","category":"page"},{"location":"misc/","page":"Further Information","title":"Further Information","text":"The arrays are thus quite similar with around 7% difference between the two and none being a subset of the other. This motivates the strategy to take the intersection of genotyping arrays before merging. Note that in reality the intersection might be smaller due to QC filtering of the input SNPs.","category":"page"},{"location":"misc/","page":"Further Information","title":"Further Information","text":"Furthermore, because the manifest files are too big to be version controlled, variants on the - RefStrand were extracted (function GenomiccWorkflows.OneTimeChecks.make_snps_to_flip_list) and stored as follows:","category":"page"},{"location":"misc/","page":"Further Information","title":"Further Information","text":"GSA-MD-24v3-0A1 (genome build GRC37) : `assets/GSA-24v3-0A1-minus-strand.txt`\nGSA-MD-48v4-0A1 (genome build GRC38) : `assets/GSA-48v4-020085471_D2-minus-strand.txt`","category":"page"},{"location":"misc/","page":"Further Information","title":"Further Information","text":"This has been done using the following command:","category":"page"},{"location":"misc/","page":"Further Information","title":"Further Information","text":"julia --project --startup-file=no bin/genomicc.jl snps-to-flip --help","category":"page"},{"location":"combining_genomicc_datasets/#Combining-GenOMICC-Datasets","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"This workflow combines the various genetic data sources available into a unified dataset.","category":"page"},{"location":"combining_genomicc_datasets/#Inputs","page":"Combining GenOMICC Datasets","title":"Inputs","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"Since GenOMICC is an ongoing project where the data is continuously collected, it came and will continue to arrive in different formats. This section describes the input data, the corresponding workflow parameters are described below.","category":"page"},{"location":"combining_genomicc_datasets/#Genetic-Data","page":"Combining GenOMICC Datasets","title":"Genetic Data","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"The pipeline requires genotyping arrays and optionally whole-genome sequencing (wgs) data.","category":"page"},{"location":"combining_genomicc_datasets/#Genotyping-Arrays","page":"Combining GenOMICC Datasets","title":"Genotyping Arrays","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"There are three filesets and three corresponding subfolders:","category":"page"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"The r8 release: Corresponds to genotyping data generated before 2021. The genotyping chip was the Illumina GSA-MD-24v3-0A1 and the associated genome build GRCh37. The corresponding subfolder is usually named `wp5-gwas-r8-under90excl2021Sep16`.\nThe 2021-2023 release:  Corresponds to genotyping data generated between 2021 and 2023. It was also genotyped using the Illumina GSA-MD-24v3-0A1 chip and the genome build is also GRCh37. The corresponding subfolder is usually named `2021092020231206QCVFinal`.\nThe 2024-now release: Corresponds to the latest fileset. The Illumina GSA-MD-48v4-0A1 chip was used and the genome build is GRCh38. The corresponding subfolder is usually named `2024060420240610QCVFinal`.","category":"page"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"In each subfolder, there is a plink subfolder which contains the actual genotypes, the following tables summarises the above","category":"page"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"Brief Description Period Begin Period End Genotyping Array Genome Build Directory Genotypes Prefix\nPrehistoric r8 release 04/05/2020 30/08/2021 GSA-MD-24v3-0_A1 GRC37 wp5-gwas-r8-under90excl_2021Sep16 PLINK1909210906/wp5-gwas-r8-under90excl_2021Sep16\nBefore 2024 microarray 20/09/2021 06/12/2023 GSA-MD-24v3-0_A1 GRC37 2021092020231206QC_VFinal PLINK0407240954/2021092020231206QC_VFinal\nSince 2024 microarray 04/06/2024 10/06/2024 GSA-MD-48v4-0_A1 GRC38 2024060420240610QC_VFinal PLINK0407240114/2024060420240610QC_VFinal","category":"page"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"So, in the example above, the R8_GENOTYPES workflow parameter (see below) should point to wp5-gwas-r8-under90excl_2021Sep16/PLINK_190921_0906/wp5-gwas-r8-under90excl_2021Sep16","category":"page"},{"location":"combining_genomicc_datasets/#Whole-Genome-Sequencing","page":"Combining GenOMICC Datasets","title":"Whole Genome Sequencing","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"The wgs GVCF files are all located in a wgs-reheadered folder.","category":"page"},{"location":"combining_genomicc_datasets/#External-Resources","page":"Combining GenOMICC Datasets","title":"External Resources","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"As well as our in-house data, the pipeline depends on external reference data. In principle these files should already be present on ODAP and there is nothing you need to do.","category":"page"},{"location":"combining_genomicc_datasets/#The-1000-GP","page":"Combining GenOMICC Datasets","title":"The 1000 GP","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"All VCF files and indexes present in this FTP folder\nThe associated 1000 GP pedigree file.","category":"page"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"These files should be stored in the same folder which is defined by the KGP_DIR (default: /mnt/odap-beegfs/software/gwas-resources/1000-genomes-HC) Nextflow parameter.","category":"page"},{"location":"combining_genomicc_datasets/#GATK","page":"Combining GenOMICC Datasets","title":"GATK","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"The reference genome published by the Broad Institute.","category":"page"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"This should be in a folder defined by the GATK_DIR (default: /mnt/odap-beegfs/software/gwas-resources/gatk) Nextflow parameter.","category":"page"},{"location":"combining_genomicc_datasets/#Running-The-Workflow","page":"Combining GenOMICC Datasets","title":"Running The Workflow","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"If the previous steps have been completed successfully you can run:","category":"page"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"taskset -c 998 nextflow run main.nf -entry CombineGeneticDatasets -c run.config -profile odap -resume -with-report -with-trace","category":"page"},{"location":"combining_genomicc_datasets/#Outputs","page":"Combining GenOMICC Datasets","title":"Outputs","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"All outputs are produced in PUBLISH_DIR (defaults to results), the main outputs of the workflow are:","category":"page"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"report.md: A report of the pipeline execution\ngenotypes.aggregated.qced.final.{bed,bim,fam}: The aggregated genotypes to be sent to sent for GenOMICC Genotypes Imputation\ncovariates.inferred.csv: The covariates inferred from the genotypes (ancestry, PCs).\nancestry/kgp_shared/kgp.merged.unrelated.shared.{bed,bim,fam}: The 1000 Genome Project genotypes corresponding to the variants in the GenOMICC cohort (can be used later on in Merging the GenOMICC and UK Biobank Cohorts)","category":"page"},{"location":"combining_genomicc_datasets/#Workflow-Parameters","page":"Combining GenOMICC Datasets","title":"Workflow Parameters","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"This is the list of all the pipeline's parameters, they can be set in the run.config file under the params section.","category":"page"},{"location":"combining_genomicc_datasets/#Input-Files","page":"Combining GenOMICC Datasets","title":"Input Files","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"These are project specific and need to be provided:","category":"page"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"R8_GENOTYPES: Prefix to release r8 genotypes (before 2021).\nBEFORE_2024_GENOTYPES: Prefix to genotypes released between 2021-2023.\nSINCE_2024_GENOTYPES: Prefix to genotypes released after 2024.\nWGS_GVCFS (optional): Prefix to whole genome sequencing files.","category":"page"},{"location":"combining_genomicc_datasets/#External-Inputs-Parameters","page":"Combining GenOMICC Datasets","title":"External Inputs Parameters","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"These are already set if you are using the odap profile.","category":"page"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"RESOURCES_DIR (default: ./assets/resources\"): Path to all external resources.\nKGP_DIR: Path to the 1000 Genome Project specific resources (see The 1000 GP).\nGATK_DIR: Path to GATK specific resources (see GATK).\nGRC37_TO_GRC38_CHAIN_FILE (default: \"./assets/hg19ToHg38.over.chain.gz\"): Path to chain file used to liftover the GRCh37 genotypes to GRCh38.","category":"page"},{"location":"combining_genomicc_datasets/#QC-Parameters","page":"Combining GenOMICC Datasets","title":"QC Parameters","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"QC_GENOTYPE_MISSING_RATE (default: 0.02): Maximum missing rate per variant across all individuals. Variants above the threshold are dropped.\nQC_INDIVIDUAL_MISSING_RATE (default: 0.02): Maximum missing rate per individual across genotypes. Individuals above the threshold are dropped.\nQC_HWE_P (default: 1e-10): Used to identify potential technical artifacts and drop variants.\nQC_HWE_K (default: 0.001): Used together with QC_HWE_P\nPCA_APPROX (default: true): Whether PCA is performed via approximation see\nFILTER_HIGH_LOADINGS_VARIANTS (default: false): Whether to drop variants with high PCA loadings. If the loadings plots exhibits a high peak you may want to turn that on.\nANCESTRY_THRESHOLD (default: 0.8): For each individual, the most likely ancestry estimate should be greater than this threshold otherwise the individual is marked as admixed.","category":"page"},{"location":"combining_genomicc_datasets/#Output-Directories-Parameters","page":"Combining GenOMICC Datasets","title":"Output Directories Parameters","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"PUBLISH_DIR (default: \"results\"): Top level directory where outputs will be output.\nKGP_PUBLISH_DIR (default: \"results/kgp\"): Where 1000 Genome Project data will be output.\nARRAY_GENOTYPES_PUBLISH_DIR (default: \"results/array_genotypes\"): Where data associated with the genotyping arrays will be output.\nWGS_PUBLISH_DIR (default: \"results/wgs\"): Where data associated with the whole-genome sequencing data will be output.\nGATK_PUBLISH_DIR (default: \"results/gatk\"): Where data associated with GATK requirements will be output.\nMERGED_PUBLISH_DIR (default: \"results/merged\"): Where the merged genetic data will be output.","category":"page"},{"location":"combining_genomicc_datasets/#Current-Limitations","page":"Combining GenOMICC Datasets","title":"Current Limitations","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"These are current limitations of the aggregation workflow:","category":"page"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"Only chromosomes 1 to 22 are processed.\nOnly bi-allelic SNPs are used.","category":"page"},{"location":"combining_genomicc_datasets/#Workflow-DAG","page":"Combining GenOMICC Datasets","title":"Workflow DAG","text":"","category":"section"},{"location":"combining_genomicc_datasets/","page":"Combining GenOMICC Datasets","title":"Combining GenOMICC Datasets","text":"<iframe src=\"../assets/combining_datasets_dag.html\" width=\"100%\" height=\"2000px\"></iframe>","category":"page"},{"location":"genotypes_imputation/#GenOMICC-Genotypes-Imputation","page":"GenOMICC Genotypes Imputation","title":"GenOMICC Genotypes Imputation","text":"","category":"section"},{"location":"genotypes_imputation/","page":"GenOMICC Genotypes Imputation","title":"GenOMICC Genotypes Imputation","text":"This workflow sends the genotypes for imputation to TOPMed, downloads and aggregates the results per chromosome. It follows the principles provided in their documentation.","category":"page"},{"location":"genotypes_imputation/","page":"GenOMICC Genotypes Imputation","title":"GenOMICC Genotypes Imputation","text":"note: Platform\nAt the moment, it is impossible to run this workflow from ODAP because the TOPMed servers have not been white listed. Instead you can run it from eddie.","category":"page"},{"location":"genotypes_imputation/#Inputs","page":"GenOMICC Genotypes Imputation","title":"Inputs","text":"","category":"section"},{"location":"genotypes_imputation/","page":"GenOMICC Genotypes Imputation","title":"GenOMICC Genotypes Imputation","text":"For this workflow to work, you will need:","category":"page"},{"location":"genotypes_imputation/","page":"GenOMICC Genotypes Imputation","title":"GenOMICC Genotypes Imputation","text":"Genotypes: likely the output of the Combining GenOMICC Datasets workflow.\nA TOPMed token: see this page.\njob ids (optional): Only to resume a crashed job.","category":"page"},{"location":"genotypes_imputation/","page":"GenOMICC Genotypes Imputation","title":"GenOMICC Genotypes Imputation","text":"Please have a look at the wokflow parameters below for how to setup the run.","category":"page"},{"location":"genotypes_imputation/#Running-The-Workflow","page":"GenOMICC Genotypes Imputation","title":"Running The Workflow","text":"","category":"section"},{"location":"genotypes_imputation/","page":"GenOMICC Genotypes Imputation","title":"GenOMICC Genotypes Imputation","text":"If the previous steps have been completed successfully you can run:","category":"page"},{"location":"genotypes_imputation/","page":"GenOMICC Genotypes Imputation","title":"GenOMICC Genotypes Imputation","text":"nextflow run main.nf -entry Imputation -profile eddie -resume -with-report -with-trace -c run.config","category":"page"},{"location":"genotypes_imputation/","page":"GenOMICC Genotypes Imputation","title":"GenOMICC Genotypes Imputation","text":"note: Crash\nThe TOPMedImputation process waits for TOPMed imputation jobs to finish, which might be longer than the maximum eddie job duration (48h) depending on the server's queue size. In that case, the workflow will crash but all the TOPMed jobs should have been submitted. Resuming the workflow will thus not work and it will try to resubmit new jobs. In order to bypass this behaviour you can pass an optional TOPMED_JOBS_LIST to proceed directly to the download stage. These job ids can be obtained from the TOPMed urls.","category":"page"},{"location":"genotypes_imputation/#Outputs","page":"GenOMICC Genotypes Imputation","title":"Outputs","text":"","category":"section"},{"location":"genotypes_imputation/","page":"GenOMICC Genotypes Imputation","title":"GenOMICC Genotypes Imputation","text":"All outputs are produced in PUBLISH_DIR (defaults to results), the main outputs of the workflow are:","category":"page"},{"location":"genotypes_imputation/","page":"GenOMICC Genotypes Imputation","title":"GenOMICC Genotypes Imputation","text":"chr_P.qced.{pgen,pvar,psam}: A set of imputed genotypes, one for each chromosome in PGEN format.","category":"page"},{"location":"genotypes_imputation/#Workflow-Parameters","page":"GenOMICC Genotypes Imputation","title":"Workflow Parameters","text":"","category":"section"},{"location":"genotypes_imputation/","page":"GenOMICC Genotypes Imputation","title":"GenOMICC Genotypes Imputation","text":"This is the list of all the pipeline's parameters, they can be set in the run.config file under the params section.","category":"page"},{"location":"genotypes_imputation/#Inputs-Parameters","page":"GenOMICC Genotypes Imputation","title":"Inputs Parameters","text":"","category":"section"},{"location":"genotypes_imputation/","page":"GenOMICC Genotypes Imputation","title":"GenOMICC Genotypes Imputation","text":"GENOTYPES_PREFIX: Prefix to genotypes files.\nTOPMED_TOKEN_FILE: Path to the file containing your TOPMed API token.","category":"page"},{"location":"genotypes_imputation/#Important-Options","page":"GenOMICC Genotypes Imputation","title":"Important Options","text":"","category":"section"},{"location":"genotypes_imputation/","page":"GenOMICC Genotypes Imputation","title":"GenOMICC Genotypes Imputation","text":"TOPMED_ENCRYPTION_PASSWORD: An encryption password\nTOPMED_JOBS_LIST: If the workflow crashes and you want to resume, list the job-ids in this file (one per line). Job ids can be obtained from the job url in TOPMed.\nN_SAMPLES_PER_IMPUTATION_JOBS (default: 10000): We can only send file of less than 200000 samples to TOPMed and the server only allows 3 jobs at a time. This number ideally splits your data in 3 roughly equal batches.\nIMPUTATION_R2_FILTER (default: 0.9): Only imputed variants passing the threshold are kept, set to 0 if you want to keep them all.","category":"page"},{"location":"genotypes_imputation/#Secondary-Options","page":"GenOMICC Genotypes Imputation","title":"Secondary Options","text":"","category":"section"},{"location":"genotypes_imputation/","page":"GenOMICC Genotypes Imputation","title":"GenOMICC Genotypes Imputation","text":"TOPMED_REFRESH_RATE (default: 180): The frequency (in seconds) with which the workflow will monitor the imputation process to send further jobs.\nTOPMED_MAX_PARALLEL_JOBS (default: 3): The maximum number of concurrent imputation processes, this is limited to 3 at the moment by TOPMed.","category":"page"},{"location":"julia_fns/#Index-of-Julia-Functions","page":"Index Of Julia Functions","title":"Index of Julia Functions","text":"","category":"section"},{"location":"julia_fns/#GenomiccWorkflows.genotype_gvcf-NTuple{4, Any}","page":"Index Of Julia Functions","title":"GenomiccWorkflows.genotype_gvcf","text":"genotype_gvcf(gvcf_file, \n    shared_variants_plink, \n    shared_variants_gatk, \n    reference_genome; \n    output_prefix=\"output\"\n)\n\nGenotype a GVCF file using GATK and PLINK as follow. \n\nFirst attempts to genotype the GVCF file using GATK (this can fail for some reason in which case we just skip the individual).\nThen converts the VCF to a PLINK bed format.\nUpdates the bim file with the mapped alleles from the shared variants (thi can also fail if some variants are not any of the known ref/alt in which case we also skip the individual).\nWrites the new bim, bed and fam files.\n\n\n\n\n\n","category":"method"},{"location":"julia_fns/#GenomiccWorkflows.get_action-Tuple{Any, Any}","page":"Index Of Julia Functions","title":"GenomiccWorkflows.get_action","text":"Compares the variant to the 1000 GP information and returns an action to take together with a reason.\n\nPotential actions are\n\nDROP\nKEEP\nFLIP\n\nSome particularly unexpected ACTION (REASON) are:\n\n\"KEEP (REVERSE-REF-ALT)\"\n\"FLIP (COMPLEMENT-NOT-MATCHING-KGP)\"\n\nBecause they mean the minor/major alleles are reversed in our dataset as compared to the reference KGP.\n\n\n\n\n\n","category":"method"},{"location":"julia_fns/#GenomiccWorkflows.kgp_unrelated_individuals-Tuple{Any}","page":"Index Of Julia Functions","title":"GenomiccWorkflows.kgp_unrelated_individuals","text":"Only keeps the first individual within each family and writes them to outfile.\n\n\n\n\n\n","category":"method"},{"location":"julia_fns/#GenomiccWorkflows.read_bim-Tuple{Any}","page":"Index Of Julia Functions","title":"GenomiccWorkflows.read_bim","text":"read_bim(file)\n\nColumns Description from: https://www.cog-genomics.org/plink/1.9/formats#bim\n\nChromosome code (either an integer, or 'X'/'Y'/'XY'/'MT'; '0' indicates unknown) or name\nVariant identifier\nPosition in morgans or centimorgans (safe to use dummy value of '0')\nBase-pair coordinate (1-based; limited to 231-2)\nAllele 1 (corresponding to clear bits in .bed; usually minor)\nAllele 2 (corresponding to set bits in .bed; usually major)\n\n\n\n\n\n","category":"method"},{"location":"julia_fns/#GenomiccWorkflows.read_fam-Tuple{Any}","page":"Index Of Julia Functions","title":"GenomiccWorkflows.read_fam","text":"read_fam(file)\n\nColumns Description from: https://www.cog-genomics.org/plink/1.9/formats#fam\n\nFamily ID ('FID')\nWithin-family ID ('IID'; cannot be '0')\nWithin-family ID of father ('0' if father isn't in dataset)\nWithin-family ID of mother ('0' if mother isn't in dataset)\nSex code ('1' = male, '2' = female, '0' = unknown)\nPhenotype value ('1' = control, '2' = case, '-9'/'0'/non-numeric = missing data if case/control)\n\n\n\n\n\n","category":"method"},{"location":"julia_fns/#GenomiccWorkflows.read_map-Tuple{Any}","page":"Index Of Julia Functions","title":"GenomiccWorkflows.read_map","text":"read_map(file)\n\nColumns Description from: https://www.cog-genomics.org/plink/1.9/formats\n\nChromosome code. PLINK 1.9 also permits contig names here, but most older programs do not.\nVariant identifier\nPosition in morgans or centimorgans (optional; also safe to use dummy value of '0')\nBase-pair coordinate\n\n\n\n\n\n","category":"method"},{"location":"julia_fns/#GenomiccWorkflows.report_qc_effect-Tuple{Any, Any}","page":"Index Of Julia Functions","title":"GenomiccWorkflows.report_qc_effect","text":"report_qc_effect(input_prefix, output_prefix)\n\nReport the effect of the QC filtering process on SNPs and samples.\n\n\n\n\n\n","category":"method"},{"location":"julia_fns/#GenomiccWorkflows.update_bim_with_mapped_alleles-Tuple{Any, Any}","page":"Index Of Julia Functions","title":"GenomiccWorkflows.update_bim_with_mapped_alleles","text":"update_bim_with_mapped_alleles(tmp_prefix, shared_variants_file)\n\n\n\n\n\n","category":"method"},{"location":"julia_fns/#GenomiccWorkflows.update_variant_ids_with_map!-Tuple{Any, Any}","page":"Index Of Julia Functions","title":"GenomiccWorkflows.update_variant_ids_with_map!","text":"update_variant_ids_with_map!(bim, variant_ids_map)\n\nUpdates the variant IDs to match the KGP if the following conditions are met:     - The position is present in the KGP dataset.     - The UKB alleles match the KGP alleles.\n\nThese variant IDs are marked for deletion and returned as a set.\n\n\n\n\n\n","category":"method"},{"location":"julia_fns/#GenomiccWorkflows.write_map-Tuple{Any, Any}","page":"Index Of Julia Functions","title":"GenomiccWorkflows.write_map","text":"write_map(file_prefix, array)\n\n\n\n\n\n","category":"method"},{"location":"julia_fns/#GenomiccWorkflows.write_release_samples_to_drop-Tuple{Any, Any}","page":"Index Of Julia Functions","title":"GenomiccWorkflows.write_release_samples_to_drop","text":"We drop duplicate individuals according to the following priority:\n\nWGS > More Recent Array > Older Array\n\n\n\n\n\n","category":"method"},{"location":"julia_fns/#GenomiccWorkflows.OneTimeChecks.array_overlap-Tuple{Any, Any}","page":"Index Of Julia Functions","title":"GenomiccWorkflows.OneTimeChecks.array_overlap","text":"array_overlap(manifest_file1, manifest_file2)\n\nTakes two manifest files from Illumina genotyping arrays and returns the intersection of the SNP names.\n\n\n\n\n\n","category":"method"},{"location":"julia_fns/#GenomiccWorkflows.OneTimeChecks.identify_snps_to_flip-Tuple{Any}","page":"Index Of Julia Functions","title":"GenomiccWorkflows.OneTimeChecks.identify_snps_to_flip","text":"identify_snps_to_flip(manifest_file)\n\nAccording to this link,  the RefStrand column in the manifest file corresponds to the standard designation for all eukaryotic organisms used by HapMap and 1000 Genomes Project. Variants with RefStrand equal to - need to be flipped to the + strand.\n\n\n\n\n\n","category":"method"},{"location":"julia_fns/#GenomiccWorkflows.OneTimeChecks.make_snps_to_flip_list-Tuple{Any, Any}","page":"Index Of Julia Functions","title":"GenomiccWorkflows.OneTimeChecks.make_snps_to_flip_list","text":"make_snps_to_flip_list(output, manifest_file)\n\nTakes a manifest file from an Illumina genotyping array and writes a list of SNPs  that are on the - strand and need to be flipped to the + strand.\n\n\n\n\n\n","category":"method"},{"location":"combining_with_ukb/#Combining-with-UK-Biobank","page":"Combining with UK Biobank","title":"Combining with UK Biobank","text":"","category":"section"},{"location":"gwas/#GWAS","page":"GWAS","title":"GWAS","text":"","category":"section"},{"location":"gwas/#Inputs","page":"GWAS","title":"Inputs","text":"","category":"section"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"This section describes the main inputs to the workflow, see further down for the associated Nextflow parameters.","category":"page"},{"location":"gwas/#Genetic-Data","page":"GWAS","title":"Genetic Data","text":"","category":"section"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"For this workflow, both genotypes and imputed genotypes are required. They will likely be the respective outputs of the Combining GenOMICC Datasets and GenOMICC Genotypes Imputation workflows, optionally merged with Combining with UK Biobank depending on your project of interest.","category":"page"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"###Â Covariates","category":"page"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"There are two main types of covariates files you can use here. ","category":"page"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"The COVARIATES file contains the usual covariates information including phenotypes and is typically provided by Dominique on a per project basis. Unfortunately, at this point, the specifications for this file have not been clearly defined. The columns of the file I have received are: genotype_file_id, age_years, sex, case_or_control, cohort, severe_cohort_primary_diagnosis, isaric_cohort_max_severity_score.\nAn optional INFERRED_COVARIATES contains covariates information that is inferred from the genetic datasets during the Combining GenOMICC Datasets workflow. This is the case for ancestry estimates for instance.","category":"page"},{"location":"gwas/#GWAS-Variables","page":"GWAS","title":"GWAS Variables","text":"","category":"section"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"You can define the phenotypes, covariates and groups via an external YAML file which looks like the following. ","category":"page"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"groupby: [\"ANCESTRY_ESTIMATE\"]\nphenotypes: [\"SEVERE_COVID_19\"]\ncovariates: [\"AGE\", \"SEX\", \"AGE_x_SEX\", \"AGE_x_AGE\"]","category":"page"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"In this example:","category":"page"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"An independent GWAS will be run for each ancestry group in the ANCESTRY_ESTIMATE column. \nThere is only one phenotype: SEVERE_COVID_19. \nThe covariates to are AGE, SEX, AGE^2 and AGE cdot AGE.","category":"page"},{"location":"gwas/#Groups","page":"GWAS","title":"Groups","text":"","category":"section"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"The groupby variables defines groups for which an independent GWAS will be run. If the groupby key is not present in the YAML file, only one GWAS will be run for the whole population.","category":"page"},{"location":"gwas/#Phenotypes","page":"GWAS","title":"Phenotypes","text":"","category":"section"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"The phenotype variables must either be case_or_control or have an existing definition based on other columns in the COVARIATES file (hardcoded), at the moment only SEVERE_COVID_19 has been defined.","category":"page"},{"location":"gwas/#Covariates","page":"GWAS","title":"Covariates","text":"","category":"section"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"The covariates variables are used as adjustment variables in the regression model. In REGENIE step 2, principal components are also added in a leave-one-chromosome-out scheme to the covariates defined here. ","category":"page"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"Again, due to the ill-definition of the covariates file, at the moment, only a subset of non-inferred covariates can be processed: AGE and SEX. Categorical covariates are one-hot encoded.","category":"page"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"note: Interaction Terms\nInteraction terms can be added to the covariate list with the _x_ delimiter.","category":"page"},{"location":"gwas/#Workflow-Parameters","page":"GWAS","title":"Workflow Parameters","text":"","category":"section"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"This is the list of all the pipeline's parameters, they can be set in the run.config file under the params section.","category":"page"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"GENOTYPES_PREFIX: Prefix to genotypes in PLINK BED format (likely the output of the Combining GenOMICC Datasets workflow).\nIMPUTED_GENOTYPES_PREFIX: Prefix to imputed genotypes in PGEN format (likely the output of the GenOMICC Genotypes Imputation workflow).\nCOVARIATES: Path to covariate file (likely the output of the Combining GenOMICC Datasets workflow)\nINFERRED_COVARIATES: Optional, path to covariates inferred from genetic data during the Combining GenOMICC Datasets workflow.\nN_PCS (default: 10): Number of principal components to compute.\nPCA_APPROX (default: true): Whether PCA is performed via approximation see\nMIN_GROUP_SIZE (default: 100): Minimum number of samples in a group to proceed to effect size estimation.\nVARIABLES_CONFIG (default: assets/variables.yaml): File containing the declaration of groups, phenotypes and covariates for the GWAS (see GWAS Variables).\nREGENIE_MAF (default: 0.01): Minor allele frequency for a variant to enter the GWAS.\nREGENIE_MAC (default: 10): Minor allele count for a variant to enter the GWAS.\nREGENIE_BSIZE (default: 1000): Regenie's block size (see the regenie docs)","category":"page"},{"location":"gwas/#Running-The-Workflow","page":"GWAS","title":"Running The Workflow","text":"","category":"section"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"If the previous steps have been completed successfully you can run on your platform (e.g. PLATFORM=eddie):","category":"page"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"nextflow run main.nf -entry GWAS -resume -profile PLATFORM -with-trace -with-report -c run.config","category":"page"},{"location":"gwas/#Outputs","page":"GWAS","title":"Outputs","text":"","category":"section"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"All outputs are produced in PUBLISH_DIR (default: results), for each group a separate folder contains:","category":"page"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"plots: Manhattan and QQ plots\nresults: A CSV file of summary statistics","category":"page"},{"location":"gwas/#Workflow-DAG","page":"GWAS","title":"Workflow DAG","text":"","category":"section"},{"location":"gwas/","page":"GWAS","title":"GWAS","text":"<iframe src=\"../assets/gwas_dag.html\" width=\"100%\" height=\"800px\"></iframe>","category":"page"},{"location":"ukb_merge/#Merging-the-GenOMICC-and-UK-Biobank-Cohorts","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"","category":"section"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"This workflow yields combined:","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"genotypes in PLINK bed format: obtained by subsampling the TOPMed UKB imputed genotypes to keep the GenOMICC variants.\nimputed genotypes in PLINK pgen format: ontained by merging UKB and GenOMICC TOPMed UKB imputed genotypes.\ncovariates containing the current age and sex of individuals\nancestry estimates: via the 1000 Genome Project","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"It is assumed that you have installed the required dependencies as explained in Working with the UKB RAP.","category":"page"},{"location":"ukb_merge/#1.-Uploading-Inputs","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"1. Uploading Inputs","text":"","category":"section"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"This section describes the main inputs to the workflow that need to be uploaded to the RAP. I recommend deviating as little as possible from the following instructions to make sure things run smoothly afterwards. In this section we will populate the assets/rap folder in this repository that we will then upload to the RAP using the upload agent.","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"In particular we need to populate the genomicc and kgp subfolders as displayed below. The hesin_critical_fields.txt and main_fields.txt should already be present.","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"(Image: rap_assets_level_1)","category":"page"},{"location":"ukb_merge/#GenOMICC-Data","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"GenOMICC Data","text":"","category":"section"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"We will need the following GenOMICC data, at the present time, the name of the file does not matter since it seems impossible to reference a file by its path on the RAP, instead we will have to use file IDs: ","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"genotypes: Output by Combining GenOMICC Datasets.\ncovariates: \nGeneral covariates provided by Dominique, it should contain an age_years and a sex column.\nInferred covariates output by Combining GenOMICC Datasets containing ancestry estimates.\nimputed genotypes: Output by GenOMICC Genotypes Imputation.","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"I recommend to organise them as follows:","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"(Image: rap_assets_genomicc)","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"note: Imputed Genotypes\nKeep the imputed genotypes organised in chromosomes. Only 3 chromosomes are presented above for readability but all 22 chromosomes should be in the folder.","category":"page"},{"location":"ukb_merge/#1000-Genome-Project","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"1000 Genome Project","text":"","category":"section"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"You will also need the 1000 Genome Project genotypes in plink format, filtered to keep only variants matching the GenOMICC genotyped variants. This is an output of the Combining GenOMICC Datasets workflow. They can be organised as follows:","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"(Image: rap_assets_kgp)","category":"page"},{"location":"ukb_merge/#Other-Assets","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Other Assets","text":"","category":"section"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"We also need the reference genome, which can be downloaded in the assets/rap folder with:","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"wget -O assets/rap/Homo_sapiens_assembly38.fasta https://storage.googleapis.com/genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta","category":"page"},{"location":"ukb_merge/#Uploading-the-data","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Uploading the data","text":"","category":"section"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"Since this is a lot of data, we need to use the upload agent. Asumming ua is in your path, run:","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"export PROJECT_ID=PPP\nexport AUTH_TOKEN=XXX\nua --project $PROJECT_ID --auth-token $AUTH_TOKEN --folder /assets assets/rap/ --recursive","category":"page"},{"location":"ukb_merge/#2.-Extracting-Phenotypes","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"2. Extracting Phenotypes","text":"","category":"section"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"At this point, it seems impossible (or very difficult) to extract phenotypes from a WDL workflow because the source dataset is not a regular file (see this or that). We thus have to first run a native DNA Nexus workflow to extract some preliminary data from the source dataset. First we build the workflow:","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"dx build rap_workflows/export_covariates","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"Then run it (replace the DATASET_RECORD_ID with the one corresponding to your project):","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"DATASET_RECORD_ID=record-J0pqJxjJZF8G55f99FF11JJ9\ndx run -y \\\n-istage-J0vx360JpYQ0Jg1QJ5Zv0PFx.dataset_or_cohort_or_dashboard=$DATASET_RECORD_ID \\\n-istage-J0vx360JpYQ0Jg1QJ5Zv0PFx.field_names_file_txt=/assets/hesin_critical_fields.txt \\\n-istage-J0ygjB0JpYQJg4b985gqYkx6.dataset_or_cohort_or_dashboard=$DATASET_RECORD_ID \\\n-istage-J0ygjB0JpYQJg4b985gqYkx6.field_names_file_txt=/assets/main_fields.txt \\\n/export_covariates","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"You can monitor the workflow on the RAP, once finished you should have two outputs in the /export_covariates_outputs folder: and.","category":"page"},{"location":"ukb_merge/#3.-Merging-Cohorts","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"3. Merging Cohorts","text":"","category":"section"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"First you need to compile the WDL workflow and upload it to the RAP, this can be done with the following:","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"export DX_COMPILER_PATH=/Users/olabayle/dxCompiler/dxCompiler-2.13.0.jar\nexport PROJECT_ID=project-J0pkqyQJpYQ133JG1p2J1qzv\njava -jar $DX_COMPILER_PATH compile rap_workflows/ukb_merge/workflow.wdl -f -project $PROJECT_ID -folder /workflows -inputs rap_workflows/ukb_merge/inputs.json","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"where the DX_COMPILER_PATH and PROJECT_ID have to be set appropriately. The compiler might output some warnings like missing input for non-optional parameter but you can ignore these.","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"Then, you can run the workflow with the following command","category":"page"},{"location":"ukb_merge/","page":"Merging the GenOMICC and UK Biobank Cohorts","title":"Merging the GenOMICC and UK Biobank Cohorts","text":"dx run -y \\\n-f rap_workflows/ukb_merge/inputs.dx.json \\\n--priority high \\\n--destination /ukb_merge_outputs/ \\\n/workflows/merge_ukb_and_genomicc","category":"page"},{"location":"#GenOMICC-Workflows","page":"Home","title":"GenOMICC Workflows","text":"","category":"section"},{"location":"#Purpose","page":"Home","title":"Purpose","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This repository provides a set of Nextflow and WdL workflows that can be used to analyse data generated by the GenOMICC project.","category":"page"},{"location":"#Cohorts","page":"Home","title":"Cohorts","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Even though our main dataset consists of GenoMICC data, for historical reasons (COVID-19 pandemic), we have a total of 4 different cohorts: GenOMICC, MILD, REACT and ISARIC. MILD, REACT and ISARIC were integrated in order to provide non severe \"controls\" for various COVID-19 susceptibility studies.","category":"page"},{"location":"#GenOMICC-(Genetics-Of-Mortality-In-Critical-Care)","page":"Home","title":"GenOMICC (Genetics Of Mortality In Critical Care)","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Link to the study webpage: https://genomicc.org/.","category":"page"},{"location":"#GenOMICC-UK","page":"Home","title":"GenOMICC UK","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Inclusion criteria:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Intensive Care Unit patients\nUK (mostly England and some specific recruitment centers if I understand correctly)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Additional Information:","category":"page"},{"location":"","page":"Home","title":"Home","text":"The study also seems to be recruiting controls by matching in some way according to this page.\nNurses select who they think might be eligible which could produce cryptic bias as well.","category":"page"},{"location":"#GenOMICC-International","page":"Home","title":"GenOMICC International","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is still being deployed and is not part of our current data.","category":"page"},{"location":"#ISARIC","page":"Home","title":"ISARIC","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Link to the study webpage: https://isaric.org/.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Inclusion criteria:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Our subset of individuals all had Covid-19","category":"page"},{"location":"","page":"Home","title":"Home","text":"Additional Information:","category":"page"},{"location":"","page":"Home","title":"Home","text":"The severity varies and a severity score is provided\nMany biological and contextual covariates exist but are sparse","category":"page"},{"location":"#MILD","page":"Home","title":"MILD","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Link to the study webpage: ?","category":"page"},{"location":"","page":"Home","title":"Home","text":"Inclusion criteria:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Covid-19\nVolunteers (It is not clear in what way?)\nNot hospitalised ","category":"page"},{"location":"#REACT-(Real-time-Assessment-of-Community-Transmission)","page":"Home","title":"REACT (Real-time Assessment of Community Transmission)","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Link to the study webpage https://www.imperial.ac.uk/medicine/research-and-impact/groups/react-study/.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Inclusion criteria:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Covid-19\nIt is unclear if they were hospitalised\nIt is unclear what the selection process is","category":"page"},{"location":"#Available-Workflows","page":"Home","title":"Available Workflows","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"These workflows will typically be run sequentially.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Combining GenOMICC Datasets\nGenOMICC Genotypes Imputation\nCombining with UK Biobank\nGWAS","category":"page"}]
}
